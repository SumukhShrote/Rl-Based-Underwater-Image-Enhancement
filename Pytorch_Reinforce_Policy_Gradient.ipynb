{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = cv2.imread('C:\\\\Users\\\\Asus\\\\Downloads\\\\frame_711.jpg')\n",
    "plt.imshow(input_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_features(image):\n",
    "    # Create ORB detector\n",
    "    orb = cv2.ORB_create()\n",
    "\n",
    "    # Detect keypoints using ORB\n",
    "    keypoints = orb.detect(image, None)\n",
    "\n",
    "    # Compute descriptors\n",
    "    keypoints, descriptors = orb.compute(image, keypoints)\n",
    "\n",
    "    # Draw the detected keypoints on the image\n",
    "    output_image = cv2.drawKeypoints(image, keypoints, None, color=(0, 255, 0), flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "    # Count the number of detected features\n",
    "    num_features = len(keypoints)\n",
    "    # print(f\"Number of ORB features detected: {num_features}\")\n",
    "\n",
    "    # Display the image with keypoints\n",
    "    # plt.imshow(output_image)\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "    \n",
    "    return num_features\n",
    "\n",
    "calculate_features(input_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of image enhancement algorithms\n",
    "image_enhancement_algorithms = ['WB','C_Up','C_Down','Bs_Up','B_Down','CLAHE']\n",
    "\n",
    "# Define state space (number of features in intervals of hundreds)\n",
    "state_space = ['F0','F1','F2','F3','F4','F5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self, num_actions):\n",
    "        super(PolicyNetwork, self).__init__()\n",
    "        self.dense1 = nn.Linear(1, 32)\n",
    "        self.dense2 = nn.Linear(32, num_actions)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.dense1(state))\n",
    "        return F.softmax(self.dense2(x), dim=-1)\n",
    "\n",
    "# Instantiate the policy network and move it to CUDA if available\n",
    "policy_net = PolicyNetwork(len(image_enhancement_algorithms))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "policy_net.to(device)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(policy_net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CLAHE(image):\n",
    "\n",
    "    if len(image.shape) == 3:\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray_image = image\n",
    "\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "\n",
    "    clahe_image = clahe.apply(gray_image)\n",
    "\n",
    "    if len(image.shape) == 3:\n",
    "        clahe_image = cv2.cvtColor(clahe_image, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    return clahe_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def white_balance(image):\n",
    "   \n",
    "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "    l, a, b = cv2.split(lab_image)\n",
    "\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "    cl = clahe.apply(l)\n",
    "\n",
    "    balanced_lab_image = cv2.merge((cl, a, b))\n",
    "\n",
    "    balanced_image = cv2.cvtColor(balanced_lab_image, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    return balanced_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Contrast_Up(image):\n",
    "    \n",
    "    contrasted_image = cv2.convertScaleAbs(image, alpha=4.0, beta=0)\n",
    "    return contrasted_image\n",
    "\n",
    "def Contrast_Down(image):\n",
    "    \n",
    "    contrasted_image = cv2.convertScaleAbs(image, alpha=0.2, beta=0)\n",
    "    return contrasted_image\n",
    "\n",
    "def Brightness_Up(image):\n",
    "    \n",
    "    brightened_image = cv2.convertScaleAbs(image, alpha=1.0, beta=150)\n",
    "    return brightened_image\n",
    "\n",
    "def Brightness_Down(image):\n",
    "    \n",
    "    darkened_image = cv2.convertScaleAbs(image, alpha=1.0, beta=10)\n",
    "    return darkened_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_action(ind,img_inp):\n",
    "        if ind == 0:\n",
    "            denoised = white_balance(img_inp)\n",
    "            return denoised\n",
    "        elif ind == 1:\n",
    "            denoised = Contrast_Up(img_inp)\n",
    "            return denoised\n",
    "        elif ind == 2:\n",
    "            denoised = Contrast_Down(img_inp)\n",
    "            return denoised\n",
    "        elif ind == 3:\n",
    "            denoised = Brightness_Up(img_inp)\n",
    "            return denoised\n",
    "        elif ind == 4:\n",
    "            denoised = Brightness_Down(img_inp)\n",
    "            return denoised\n",
    "        elif ind == 5:\n",
    "            denoised = CLAHE(img_inp)\n",
    "            return denoised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_state(image):\n",
    "        num_of_features = calculate_features(image)\n",
    "        if num_of_features < 0:\n",
    "            return 'F0'\n",
    "        elif num_of_features >= 0 and num_of_features < 100 :\n",
    "            return 'F1'\n",
    "        elif num_of_features <=200 and num_of_features > 100:\n",
    "            return 'F2'\n",
    "        elif num_of_features <=300 and num_of_features > 200:\n",
    "            return 'F3'\n",
    "        elif num_of_features <=400 and num_of_features > 300:\n",
    "            return 'F4'\n",
    "        elif  num_of_features > 400:\n",
    "            return 'F5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_state(image ,action):\n",
    "        next_img = perform_action(action,image)\n",
    "        return [next_img,check_state(next_img)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_value(ft1):\n",
    "        i1 = state_space.index(ft1)\n",
    "        return i1*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_reward(img1,img2):\n",
    "        feature_difference = calculate_features(img1) - calculate_features(img2)\n",
    "        \n",
    "        if feature_difference <0:\n",
    "            return -5\n",
    "        elif feature_difference == 0:\n",
    "            return -1\n",
    "        elif feature_difference <= 100 and feature_difference > 0:\n",
    "            return 1\n",
    "        elif feature_difference <= 200 and feature_difference > 100:\n",
    "            return 2\n",
    "        elif feature_difference <= 300 and feature_difference > 200:\n",
    "            return 3\n",
    "        elif feature_difference <= 400 and feature_difference > 300:\n",
    "            return 4\n",
    "        elif feature_difference > 400 :\n",
    "            return 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_REINFORCE(num_episodes, discount_factor, input_img):\n",
    "    cumulative_reward = 0\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        state = state_space[np.random.choice(len(state_space))]  # Random initial state\n",
    "        state_tensor = torch.tensor([[get_feature_value(state)]], dtype=torch.float32).to(device)\n",
    "        curr_image = input_img\n",
    "\n",
    "        action_probs = policy_net(state_tensor)\n",
    "        action_distribution = torch.distributions.Categorical(probs=action_probs)\n",
    "        action = action_distribution.sample().item()\n",
    "        #action = int(action.numpy())\n",
    "        \n",
    "        if action == 0:\n",
    "            nxt_state =  next_state(curr_image,0)\n",
    "            next_state_tensor = torch.tensor([[get_feature_value(nxt_state[1])]], dtype=torch.float32)\n",
    "            den_img = nxt_state[0]\n",
    "            reward = update_reward(den_img,curr_image)\n",
    "            cumulative_reward += reward\n",
    "        \n",
    "        elif action == 1:\n",
    "            nxt_state =  next_state(curr_image,1)\n",
    "            next_state_tensor = torch.tensor([[get_feature_value(nxt_state[1])]], dtype=torch.float32)\n",
    "            den_img = nxt_state[0]\n",
    "            reward = update_reward(den_img,curr_image)\n",
    "            cumulative_reward += reward\n",
    "            \n",
    "        elif action == 2:\n",
    "            nxt_state =  next_state(curr_image,2)\n",
    "            next_state_tensor = torch.tensor([[get_feature_value(nxt_state[1])]], dtype=torch.float32)\n",
    "            den_img = nxt_state[0]\n",
    "            reward = update_reward(den_img,curr_image)\n",
    "            cumulative_reward += reward\n",
    "        \n",
    "        elif action == 3:\n",
    "            nxt_state =  next_state(curr_image,3)\n",
    "            next_state_tensor = torch.tensor([[get_feature_value(nxt_state[1])]], dtype=torch.float32)\n",
    "            den_img = nxt_state[0]\n",
    "            reward = update_reward(den_img,curr_image)\n",
    "            cumulative_reward += reward\n",
    "            \n",
    "        elif action == 4:\n",
    "            nxt_state =  next_state(curr_image,4)\n",
    "            next_state_tensor = torch.tensor([[get_feature_value(nxt_state[1])]], dtype=torch.float32)\n",
    "            den_img = nxt_state[0]\n",
    "            reward = update_reward(den_img,curr_image)\n",
    "            cumulative_reward += reward\n",
    "        elif action == 5:\n",
    "            nxt_state =  next_state(curr_image,5)\n",
    "            next_state_tensor = torch.tensor([[get_feature_value(nxt_state[1])]], dtype=torch.float32)\n",
    "            den_img = nxt_state[0]\n",
    "            reward = update_reward(den_img,curr_image)\n",
    "            cumulative_reward += reward\n",
    "\n",
    "        \n",
    "        loss = -torch.log(action_probs[0][action]) * reward\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        curr_image = den_img\n",
    "\n",
    "        if get_feature_value(check_state(den_img)) - get_feature_value(state) > 400:\n",
    "            break\n",
    "        \n",
    "        print(f\"Episode {episode + 1}: State={state}, Action={image_enhancement_algorithms[action]}, Reward={reward}, Cumulative Reward={cumulative_reward}\")\n",
    "        plt.imshow(curr_image)\n",
    "\n",
    "# Training parameters\n",
    "num_episodes = 1000\n",
    "discount_factor = 0.99\n",
    "\n",
    "# Train the agent\n",
    "train_REINFORCE(num_episodes, discount_factor, input_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_REINFORCE(num_episodes, discount_factor, input_img):\n",
    "    cumulative_reward = 0\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        state = state_space[np.random.choice(len(state_space))]  # Random initial state\n",
    "        state_tensor = torch.tensor([[get_feature_value(state)]], dtype=torch.float32).to(device)\n",
    "        curr_image = input_img\n",
    "        num_steps = 0\n",
    "\n",
    "        while True:\n",
    "            action_probs = policy_net(state_tensor)\n",
    "            action_distribution = torch.distributions.Categorical(probs=action_probs)\n",
    "            action = action_distribution.sample().item()\n",
    "            \n",
    "            nxt_state, nxt_state_label = next_state(curr_image, action)\n",
    "            next_state_tensor = torch.tensor([[get_feature_value(nxt_state_label)]], dtype=torch.float32).to(device)\n",
    "            \n",
    "            reward = update_reward(nxt_state, curr_image)\n",
    "            cumulative_reward += reward\n",
    "            \n",
    "            loss = -torch.log(action_probs[0][action]) * reward\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            curr_image = nxt_state\n",
    "            num_steps += 1\n",
    "            print(num_steps)\n",
    "            if get_feature_value(nxt_state_label) - get_feature_value(state) > 400:\n",
    "                break\n",
    "\n",
    "            if num_steps > 99:\n",
    "                break\n",
    "\n",
    "        print(f\"Episode {episode + 1}: State={state}, Action={image_enhancement_algorithms[action]}, Reward={reward}, Cumulative Reward={cumulative_reward}\")\n",
    "        plt.imshow(curr_image)\n",
    "        plt.show()\n",
    "\n",
    "# Training parameters\n",
    "num_episodes = 1000\n",
    "discount_factor = 0.99\n",
    "\n",
    "# Train the agent\n",
    "train_REINFORCE(num_episodes, discount_factor, input_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(curr_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
